a2.sources = s1
a2.sinks = k1
a2.channels = c1

a2.sources.s1.type = netcat
a2.sources.s1.bind = 127.0.0.1
a2.sources.s1.port = 25001

a2.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a2.sinks.k1.topic = ods_mall_log
a2.sinks.k1.brokerList = 192.168.45.13:9092

a2.channels.c1.type = memory

a2.sources.s1.channels = c1
a2.sinks.k1.channel = c1


在Master节点进入到maxwell-1.29.0的解压后目录下（在/opt/module），
配置相关文件并启动，
读取MySQL数据的binlog日志（mysql的binlog相关配置已完毕）到Kafka的Topic中（Topic名称为ods_mall_data，分区数为4）。
将order_master和order_detail中的数据创建为fact_order_master和fact_order_detail，
存储在Kafka的topic为ods_mall_data中，使用Kafka自带的消费者消费ods_mall_data（Topic）中的数据，查看前2条数据的结果；


$"order_sn",
$"customer_id",
$"hipping_user",
$"province",
$"city",
$"address",
$"order_source",
$"payment_method",
$"order_money",
$"district_money",
$"shipping_money",
$"payment_money",
$"shipping_sn",
$"create_time",
$"hipping_time",
$"pay_time",
$"receive_time",
$"order_status",
$"invoice_title",
$"modified_time",



$"order_detail_id",
$"order_sn",
$"product_id",
$"product_name",
$"product_nct",
$"product_price",
$"average_cost",
$"weight",
$"fee_money",
$"w_id",
$"create_time",
$"modified_time",


CREATE EXTERNAL TABLE ads.online_uv_pv(
    key bigint,
    product_id BIGINT,
    product_name STRING,
    uv BIGINT,
    pv BIGINT,
    modified_time string
) ROW FORMAT SERDE 'org.apache.hadoop.hive.hbase.HBaseSerDe'
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
with serdeproperties(
'hbase.columns.mapping'=':key,
    info:product_id,
    info:product_name,
    info:uv,
    info:pv,
    info:modified_time')
tblproperties('hbase.table.name'='ods:TempTable','hbase.table.default.storage.type'='binary');



$"order_id"
$"order_sn"
$"customer_id"
$"shipping_user"
$"province"
$"city"
$"address"
$"order_source"
$"payment_method"
$"order_money"
$"district_money"
$"shipping_money"
$"payment_money"
$"shipping_comp_name"
$"shipping_sn"
$"create_time"
$"shipping_time"
$"pay_time"
$"receive_time"
$"order_status"
$"order_point"
$"invoice_title"
$"modified_time"


CREATE EXTERNAL TABLE ads.online_uv_pv(
    key STRING,
    product_id BIGINT,
    product_name STRING,
    uv BIGINT,
    pv BIGINT
) ROW FORMAT SERDE 'org.apache.hadoop.hive.hbase.HBaseSerDe'
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
with serdeproperties('hbase.columns.mapping'=':key,info:product_id,info:product_name,info:uv,info:pv')
tblproperties('hbase.table.name'='ads:online_uv_pv','hbase.table.default.storage.type'='binary');




a1.sinks = k1
a1.channels = c1
a1.sources = s1

a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.brokerList = 192.168.45.10:9092
a1.sinks.k1.topic = xxx

a1.sources.s1.type = netcat
a1.sources.s1.bind = 127.0.0.1
a1.sources.s1.port = xxxx

a1.channels.c1.type = memory

a1.sinks.k1.channels = c1
a1.sources.s1.channels = c1


CREATE EXTERNAL TABLE ads.online_uv_pv(
    key STRING,
    product_id BIGINT,
    product_name STRING,
    uv BIGINT,
    pv BIGINT
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.hbase.HBaseSerDe'
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
with serdeproperties('hbase.columns.mapping'=':key,info:product_id,info:product_name,info:uv,info:pv')
tblproperties('hbase.table.name'='ads:online_uv_pv','hbase.table.default.storage.type'='binary');







CREATE TABLE IF NOT EXISTS ds_result.payment_cvr(province String, creat_order UInt64,payment UInt64,payCVR Float64, ranking UInt64) ENGINE = MergeTree() ORDER BY ranking;
















